---
title: "Project Report"
author: "Kevin Zhang"
date: "6/5/2020"
output:
  html_document:
    code_folding: hide
---

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(keras)
library(modelr)
library(tensorflow)
library(caret)
library(janitor)
library(lubridate)
library(glmnet)
library(glmnetUtils)
library(kernlab)
library(gridExtra)
library(ggdendro)
library(magrittr)
library(corrplot)
library(usmap)

set.seed(9254853)

# Load Data ---------------------------------------------------------------

# 5/9/20 Daily report:
daily_report <- read_csv("data/unprocessed/csse_covid_19_data/csse_covid_19_daily_reports/05-09-2020.csv") %>%
  clean_names()

# Time series:
confirmed_ts <- read_csv("data/unprocessed/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv") %>%
  clean_names()

deaths_ts <- read_csv("data/unprocessed/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv") %>%
  clean_names()

recovered_ts <- read_csv("data/unprocessed/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv") %>%
  clean_names()
```


# Executive Summary

The objective of this project is to develop models which can create forecasts for the future trajectory of total COVID-19 deaths. For this project, I focused on US data for the pandemic, and trained models using daily observations by state. The predictors used were primarily lagged daily death counts as well as lagged rolling means for various mobility indicators during the interval 2-4 weeks prior to each day for which predictions are made. Although various data was analyzed to be potentially used as predictors, much of the data didn't show much relation to the death totals from the pandemic. 

From the predictors chosen, models were trained using Deep Learning (Keras), Random Forests, Ridge Regression (glmnet), and Boosting (xgboost). One ensemble model was created using the other four trained models. The models were then evaluated based on how well they could predict future death counts on both a national and state level. The graphic below shows each model's performance on a national level.

```{r, message = FALSE, warning = FALSE}
rf <- read_csv("outcomes/rf.csv") %>%
  mutate(
    model = rep("RF", nrow(.))
  )

deep_learning <- read_csv("outcomes/deep_learning.csv") %>%
  mutate(
    model = rep("Keras", nrow(.))
  )

ridge <- read_csv("outcomes/ridge.csv") %>%
  mutate(
    model = rep("Ridge", nrow(.))
  )

boosting <- read_csv("outcomes/boosting.csv") %>%
  mutate(
    model = rep("xgboost", nrow(.))
  )

real_values <- rf %>%
  mutate(pred_change = change,
         pred_total = total_deaths,
         model = "Reported Deaths")


outcomes <- rf %>%
  bind_rows(deep_learning, ridge, boosting, real_values)

# Create Ensemble model:
ensemble <- outcomes %>%
  filter(model != "Reported Deaths") %>%
  group_by(state, date) %>%
  summarise(pred_change = mean(pred_change),
            pred_total = mean(pred_total)) %>%
  ungroup() %>%
  mutate(total_deaths = rf$total_deaths,
         change = rf$change,
         model = "Ensemble") %>%
  select(state, date, total_deaths, change, pred_change, pred_total, model)


outcomes <- outcomes %>%
  bind_rows(ensemble)
 
outcomes %>%
  group_by(date, model) %>%
  summarise(pred_change = sum(pred_change),
            pred_total = sum(pred_total)) %>%
  ggplot(aes(date, pred_total)) +
  geom_line(aes(color = model)) +
  labs(title = "Model Performance - Predicted National Death Totals")
```

From the current results, it looks as if Ridge Regression performed the best on both a state and national level; still, all models showed a trend of overpredicting the number of deaths, and models were susceptible to sometimes predicting negative daily death counts. These are the current issues with the models. Further interpretation of the data, as well as incorporating additional data which captures trends that the models are currently unable to accurately predict for, may help improve the models. 

# Main Report

## Data Overview

For the purposes of model-building, I drew data from two sources: Johns Hopkins University's COVID-19 repository, and Google's COVID-19 Community Mobility Reports. Apple's Mobility Trends Reports were also read in during data processing, but were ultimately discarded during the model-building process.

Additional data sources were used in the EDA. These will be listed in the EDA section in the appendix.

Within the JHU repository, the only dataset used for model-building purposes was the US death total time-series dataset.

Additional details on the data will be discussed in the data processing section in the appendix.

When processed and setup for model-building, the data consisted of 32 variables. Each observation represents data for a given state and day. The data was split into a training and testing set, with the training set containing dates ranging from March 7th to May 18th (3723 observations in total), and the testing set containing dates ranging from May 19th to June 1st(714 observations in total). 

## Model Building

Five candidate models were developed for this project. The five methods used were Neural Networks(Keras), Random Forests(ranger), Ridge Regression(glmnet), Boosting(xgboost), and an ensemble model using these four methods, equally weighted. 

The response variable for the data was the number of deaths reported in a given date and state (`change`), and the same 28 predictors were used for each model: The day of the week, the 1-14 day lag on `change`, the 2-3 week lagged mean for the six Google mobility predictors: retail and recreation, workplace, transit, grocery and pharmacy, parks, and residential, the 3-4 week lagged mean for these six predictor, and finally a count on how many days have passed since the given state reported its first COVID-19 death.



### Neural Networks

The process of model building with Keras began with scaling the training and testing set using means and standard deviations from the training data. Then, two networks were trained. A validation set comprising of 20% of the training data was used to evaluate the networks:

Finding a good network for training the data was largely done through trial and error. Various numbers of hidden units were used to train networks, and the two networks described below were two of the best performing networks.

The first network used 3 layers with the first two layers using 8 hidden units. As usual with regression problems, MSE was used as the loss function and MAE as the accuracy metric. The results are shown below, when training with a batch size of 32 and 500 epochs:

```{r, message = FALSE, warning = FALSE}
history_keras <- read_rds("deep_learning/history_keras.rds")

plot(history_keras)
```


The second network used 16 hidden units for the first two layers. The results for the same batch size and 500 epochs are shown below:

```{r, message = FALSE, warning = FALSE}
history_keras <- read_rds("deep_learning/history_keras_2.rds")

plot(history_keras)
```

From these two plots, the final selected model was trained using 16 hidden units and 40 epochs. 

### Random Forests

Random forest models were trained using cross-validation. The training data was split into 5 folds, and 10 values of `mtry` between 1 and 28, as well as 10 values of `num.trees` between 200 and 1000 were evaluated with cross validation. After cross-validation, the results were as follows:

```{r, message = FALSE, warning = FALSE}
rf_cv_err <- read_csv("outcomes/rf_cv_err.csv")

# find cv error means:
rf_cv_err <- rf_cv_err %>%
  group_by(mtry, num.trees) %>%
  summarise(
    mean_train_err = mean(train_err),
    mean_test_err = mean(test_err)
  ) %>%
  arrange(mean_test_err)

rf_cv_err %>% 
  ggplot(aes(mtry, num.trees)) +
  geom_tile(aes(fill = mean_test_err)) +
  labs(title = "Heatmap of tuning parameters: Darker shades indicate better test error!")
```

The best parameters were found to be `mtry` = 7 and `num.trees` = 300. Using these parameters, the final model was trained.

## Ridge Regression

Using glmnet cross validation, the training set was trained on 400 different lambda values from 1e-10 to 1e10. The results of cross validation are as shown below:

```{r, message = FALSE, warning = FALSE}
# Load Data ---------------------------------------------------------------

data <- read_csv("data/processed/modelling_data.csv") %>%
  clean_names()

# Cut off early dates for which data is not fully available, and filter out states/territories w/ missing data:
data <- data %>% filter(date >= "2020-03-07") %>%
  filter(!(state %in% c("Virgin Islands",
                        "Northern Mariana Islands",
                        "American Samoa",
                        "Diamond Princess",
                        "Grand Princess",
                        "Guam",
                        "Puerto Rico"))) %>%
  mutate(weekday = as.factor(weekday))

data <- data %>%
  select(-driving, -driving_lag14, -driving_lag21, -rollmean_driving, -(20:32), -first_death)

train <- data %>%
  filter(date <= "2020-05-18")

test <- data %>%
  filter(date > "2020-05-18")


# Ridge Regression --------------------------------------------------------

# lambda grid to search -- use for ridge regression (400 values)
lambda_grid <- 10^seq(-10, 10, length = 400)

# ridge regression: 10-fold cv
ridge_cv <- train %>% 
  cv.glmnet(
    formula = change ~ . - state - date - total_deaths, 
    data = ., 
    alpha = 0, 
    nfolds = 10,
    lambda = lambda_grid
  )

plot(ridge_cv)
```

From this cross-validation a minimum lambda value of 10.6554 was chosen and a 1se lambda value of 120.282 was chosen. Two final models were chosen based on these lambda values. Ultimately, the minimum lambda model performed better on the test set and was thus chosen to be used in the final model comparison.

### Boosting:

Model-building for boosting followed a similar pattern to Random Forests, but only one parameter was tuned a time due to training times being unreasonably high for cross-validating on multiple parameters at a time. The parameters tuned were `eta`, `max_depth` `min_child_weight`, `gamma`, and `colsample_bytree` in their respective order, and tuning for the optimal `nrounds` at the end. These parameters were used to build the final model.

## Ensemble Model

An ensemble model was built using the evenly-weighted mean of each model for every prediction. This approach aims to increase predictive power by using the predictions of all models together. Often this sort of an approach can improve predictive power beyond any of the individual models, so it should certainly be tried.

## Model Predictions:

Given that we are predicting future observations while using lag variables, we need to assume that from the period from May 19th to June 1st, no data is known about the daily reported deaths. This means that, for example, on May 21st, we know every lag variable corresponding to data from before May 19th (which would be lag data from 3-14 days ago), but we don't know the 2 day lag and 1 day lag. However, in the testing dataset, the 2 day lag and 1 day lag from the actual number of reported deaths on May 19th and 20th were present in the data.

To solve this issue, I wrote code that iterated through the test data starting from May 19th. The code generated a prediction, then updated the 1 day lag on May 20th with that prediction, the 2 day lag on May 21st, etc., iterating through 13 of the 14 lag columns. Predictions generated for successive days used real data from days before May 19th, and predicted data from May 19th and after.

## Final Model Selection

To compare final models, I first visualized each model by comparing the predicted total deaths over the 2 week period from May 19th to June 1st to the actual number of reported deaths. Here are the results:

```{r, message = FALSE, warning = FALSE}
 
outcomes %>%
  group_by(date, model) %>%
  summarise(pred_change = sum(pred_change),
            pred_total = sum(pred_total)) %>%
  ggplot(aes(date, pred_total)) +
  geom_line(aes(color = model)) +
  labs(title = "Model Performance - Predicted National Death Totals")

```

Next, I created the same plot, but on a state level, for a few states:

```{r, message = FALSE, warning = FALSE}

outcomes %>%
  filter(state == "New York") %>%
  group_by(date, model) %>%
  summarise(pred_change = sum(pred_change),
            pred_total = sum(pred_total)) %>%
  ggplot(aes(date, pred_total)) +
  geom_line(aes(color = model)) +
  labs(title = "Model Performance - New York Death Totals")

outcomes %>%
  filter(state == "Minnesota") %>%
  group_by(date, model) %>%
  summarise(pred_change = sum(pred_change),
            pred_total = sum(pred_total)) %>%
  ggplot(aes(date, pred_total)) +
  geom_line(aes(color = model)) +
  labs(title = "Model Performance - Minnesota Death Totals")

outcomes %>%
  filter(state == "Florida") %>%
  group_by(date, model) %>%
  summarise(pred_change = sum(pred_change),
            pred_total = sum(pred_total)) %>%
  ggplot(aes(date, pred_total)) +
  geom_line(aes(color = model)) +
  labs(title = "Model Performance - Florida Death Totals")

outcomes %>%
  filter(state == "Alabama") %>%
  group_by(date, model) %>%
  summarise(pred_change = sum(pred_change),
            pred_total = sum(pred_total)) %>%
  ggplot(aes(date, pred_total)) +
  geom_line(aes(color = model)) +
  labs(title = "Model Performance - Alabama Death Totals")

outcomes %>%
  filter(state == "California") %>%
  group_by(date, model) %>%
  summarise(pred_change = sum(pred_change),
            pred_total = sum(pred_total)) %>%
  ggplot(aes(date, pred_total)) +
  geom_line(aes(color = model)) +
  labs(title = "Model Performance - California Death Totals")

outcomes %>%
  filter(state == "Montana") %>%
  group_by(date, model) %>%
  summarise(pred_change = sum(pred_change),
            pred_total = sum(pred_total)) %>%
  ggplot(aes(date, pred_total)) +
  geom_line(aes(color = model)) +
  labs(title = "Model Performance - Montana Death Totals")

outcomes %>%
  filter(state == "Kansas") %>%
  group_by(date, model) %>%
  summarise(pred_change = sum(pred_change),
            pred_total = sum(pred_total)) %>%
  ggplot(aes(date, pred_total)) +
  geom_line(aes(color = model)) +
  labs(title = "Model Performance - Kansas Death Totals")
```

As can be seen in the state models, there are some problems with the models predicting total deaths to decrease. I'll discuss this issue in a later section.

When choosing a final model, we need to consider whether or not it will be used to predict state totals or national totals. To differentiate, I calculated two types of MSE - a state level MSE which calculates each individual observation, and a national level MSE which sums the predicted daily death counts for every state together to produce a national day-by-day predicted death count. The national and state level MSEs are shown for each model on the scatterplot below:

```{r, message = FALSE, warning = FALSE}
# Calculate national and state level MSE
# National MSE
mean_state_mse <- outcomes %>%
  group_by(model) %>%
  summarise(state_mse = mean((pred_change - change)^2))

national_mse <- outcomes %>%
  group_by(model, date) %>%
  summarise(change = sum(change),
            pred_change = sum(pred_change)) %>%
  ungroup() %>%
  group_by(model) %>%
  summarise(national_mse = mean((pred_change - change) ^2))

national_mse %>%
  left_join(mean_state_mse, by = "model") %>%
  ggplot(aes(national_mse, state_mse)) +
  geom_point(aes(color = model))

```

From the current results, it appears that Ridge Regression performs the best on both a state and national level. As such, it should be chosen as the final model, since the goal of this project is to forecast the number of COVID-19 deaths in the US as accurately as possible. Ridge Regression performs the best in this aspect on both a state and national level.  

## Summary & Insights

Our original problem was predicting future death counts of the COVID-19 across the United States and its individual states. The methodology used is capable of predicting real future death counts, since it wouldn't need to rely on future data. The results of the models, although flawed in many ways, did a reasonable job of predicting within a 2 week interval given the unpredictability of the COVID-19 pandemic.

The flaws with the models were clear. First of all, there was a clear pattern of overpredicting the number of deaths nationally - every model did it. There are some possible explanations for this: the overall trend nationwide has been a decrease in death counts. Perhaps the models didn't capture this fully. Additionally, the usual trend is that death counts usually dip in the weekend then increase on Monday. However, May 25th was Memorial Day and saw a continued decrease from Sunday.

Additionally, the models sometimes predicted a negative change in total deaths for some states. This may be in part due to the presence of such negative counts in the training set - these might be caused by reporting errors, but the models do not know that. One way to address this issue might be using rolling averages of death counts, but whether or not the models would be better off overall when using those is unclear.

Finally, one major shortcoming with the model is that it can only predict up to two weeks into the future. This is because the model relies on mobility data which is lagged 2-4 weeks behind the current data. Any predictions beyond two weeks would require future mobility data, which obviously is not available when making actual future predictions. This problem might be addressed by making assumptions about how mobility will change going into the future, or even trying to predict future mobility data. So far I have not attempted to do these things in my project.

Overall, the biggest challenge with this problem is trying to capture as much useful data as possible to be used in the modeling, since there is a lot of things we don't know - how does climate affect the spread of the virus? We don't find a great deal of variation in climate with only US data. What are the optimal conditions for virus spreading? What's the current hospital usage and capacity for each state (this data was present in the daily_reports dataset but was incomplete, so I decided not to use it). How much more relevant information can be captured by using data on a county level? I may experiment with using county level data in the future; however, this will greatly increase the size of the datasets, and some procedures such as cross-validation tuning of multiple parameters at once, will certainly be near impossible. Ultimately, there was plenty of information which could be fed into the models but I ultimately excluded. I will likely continue experimenting with how this data affects the predictions.

# Appendix

## EDA

### Introduction

With the ongoing COVID-19 pandemic, many are relying on predictive models to better understand the future trajectory of the disease's impact on countries across the world. Since there is a great deal of data available on the pandemic, I decided to try and use these resources to create my own predictive model, and, in the process, hopefully come to better understand how COVID-19 impacts different communities and populations.


### About the Data

The main source of data regarding COVID-19 was obtained from the Johns Hopkins University CSSE. The data from this repository which I used included daily reports and time series data for the US and all other affected countries. For global data, the daily reports contained 3232 observations of 12 variables, the confirmed cases time series data contained 266 observations of 113 variables, the deaths time series data had 266 observations of 113 variables, and the recovered time series data contained 252 observations of 113 variables. 

The patterns of missingness in each of these datasets are as follows:

```{r, message = FALSE, warning = FALSE}
# Missing data:
daily_report %>% summarise_all(funs(mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = 1:12, names_to = "var", values_to = "percent_missing") %>%
  ggplot(aes(percent_missing, var)) +
  geom_bar(stat = "identity", aes(fill = var)) +
  labs(title = "Missing data: Daily Report")

confirmed_ts %>% summarise_all(funs(mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = 1:113, names_to = "var", values_to = "percent_missing") %>%
  filter(percent_missing > 0) %>% # There are a lot of variables, so I'm only choosing the ones with any missing data
  ggplot(aes(percent_missing, var)) +
  geom_bar(stat = "identity", aes(fill = var)) +
  labs(title = "Missing data: Confirmed Cases Time Series")

deaths_ts %>% summarise_all(funs(mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = 1:113, names_to = "var", values_to = "percent_missing") %>%
  filter(percent_missing > 0) %>% # There are a lot of variables, so I'm only choosing the ones with any missing data
  ggplot(aes(percent_missing, var)) +
  geom_bar(stat = "identity", aes(fill = var)) +
  labs(title = "Missing data: Deaths Time Series")

recovered_ts %>% summarise_all(funs(mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = 1:113, names_to = "var", values_to = "percent_missing") %>%
  filter(percent_missing > 0) %>% # There are a lot of variables, so I'm only choosing the ones with any missing data
  ggplot(aes(percent_missing, var)) +
  geom_bar(stat = "identity", aes(fill = var)) +
  labs(title = "Missing data: Recovered Time Series")
```

In general, there was not much actual missing data in the datasets; for example, `admin2` was used for US county names, so other countries had a missing value for it. The same is true for other missing values, except for `lat` and `long`, which indicated latitude and longitude--however, I do not plan on using these two variables.

</br>

#### Other Data

Many other data sources were used in this data analysis. Four datasets were retrieved from the American Community Survey (ACS) on the US Census Bureau's COVID-19 website. These datasets contained various statistics about population, income, health insurance, and internet usage, all on a state level. The purpose of this data for my analyses is to try and find any statistics that may be correlated with COVID-19 statistics.

Additionally, I used a dataset giving statistics on each state's population numbers. This was used to supplement the ACS data.

Finally, I used data from Google on mobility trends across the United States during the COVID-19 pandemic. I used this data to analyze how reduced mobility affects the trajectory of the pandemic.

</br>

### Analysis of Primary Dataset

My data analysis of the primary JHU CSSE dataset involved looking at distributions of response variables such as confirmed cases. I used linear and logarithmic scales to visualize the data, but given the shape of the data, logarithmic scales show the data much better, which can be seen in these visualizations, showing the distribution of the latest numbers of cases, deaths, and recoveries by country:

```{r, message = FALSE, warning = FALSE}
daily_report %>% # All Response
  group_by(country_region) %>%
  summarise(total_confirmed = sum(confirmed),
            total_deaths = sum(deaths),
            total_recovered = sum(recovered)) %>%
  pivot_longer(cols = c(2:4), names_to = "var") %>%
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~var) +
  labs(title = "Distribution of Confirmed Cases, Deaths, and Recoveries by Country - Linear")

daily_report %>% # All response variables on a log-10 scale
  group_by(country_region) %>%
  summarise(log_confirmed = log10(sum(confirmed)),
            log_deaths = log10(sum(deaths)),
            log_recovered = log10(sum(recovered))) %>%
  pivot_longer(cols = 2:4, names_to = "var") %>%
  ggplot(aes((value))) +
  geom_freqpoly(aes(color = var)) +
  labs(title = "Distribution of Confirmed Cases, Deaths, and Recoveries by country - Logarithmic")
```

Next, I plotted time series data on a global scale:

```{r, message = FALSE, warning = FALSE}
# Putting all time series info into one graphic:
confirmed_all_countries <- confirmed_ts %>% # Total cases over time
  select(-province_state, -lat, -long) %>%
  pivot_longer(cols = c(2:110), names_to = "date", values_to = "cases") %>%
  mutate(date = as_date(date, format = "x%m_%d_%y")) %>% # Convert date to a date variable
  group_by(date) %>%
  summarise(total_cases = sum(cases))

deaths_all_countries <- deaths_ts %>% # Total deaths over time
  select(-province_state, -lat, -long) %>%
  pivot_longer(cols = c(2:110), names_to = "date", values_to = "deaths") %>%
  mutate(date = as_date(date, format = "x%m_%d_%y")) %>% # Convert date to a date variable
  group_by(date) %>%
  summarise(total_deaths = sum(deaths))

recovered_all_countries <- recovered_ts %>% # Total recovered over time
  select(-province_state, -lat, -long) %>%
  pivot_longer(cols = c(2:110), names_to = "date", values_to = "recovered") %>%
  mutate(date = as_date(date, format = "x%m_%d_%y")) %>% # Convert date to a date variable
  group_by(date) %>%
  summarise(total_recovered = sum(recovered))

worldwide_ts <- confirmed_all_countries %>%
  left_join(deaths_all_countries, by = "date") %>%
  left_join(recovered_all_countries, by = "date")

worldwide_ts %>% pivot_longer(cols = 2:4, names_to = "type") %>% # Linear scale
  ggplot(aes(date, value)) +
  geom_line(aes(color = type)) +
  labs(title = "Worldwide cases, deaths, and recoveries over time - Linear")

worldwide_ts %>% pivot_longer(cols = 2:4, names_to = "type") %>% # Log scale
  ggplot(aes(date, log10(value))) +
  geom_line(aes(color = type)) +
  labs(title = "Worldwide cases, deaths and recoveries over time - Logarithmic")
```

Next, I wanted to look at some of the countries most impacted by COVID-19. The confirmed cases over time are displayed for the 10 countries with the most current cases on a linear and logarithmic scale as follows:

```{r}
# Time - series for top 10 countries by confirmed cases
top10 <- daily_report %>% group_by(country_region) %>% # 10 countries with most cases
  summarise(total_cases = sum(confirmed)) %>%
  arrange(desc(total_cases)) %>%
  mutate(rank = min_rank(-total_cases)) %>%
  filter(rank <= 10) %>%
  pull(country_region)

confirmed_ts %>% # Total cases over time - top 10 countries - linear scale
  select(-province_state, -lat, -long) %>%
  pivot_longer(cols = c(2:110), names_to = "date", values_to = "cases") %>%
  mutate(date = as_date(date, format = "x%m_%d_%y")) %>% # Convert date to a date variable
  filter(country_region %in% top10) %>%
  group_by(country_region, date) %>%
  summarise(total_cases = sum(cases)) %>%
  ggplot(aes(date, total_cases)) +
  geom_line(aes(color = country_region)) +
  labs(title = "10 Countries with most cases - linear time series")
  

confirmed_ts %>% # Total cases over time - top 10 countries - log scale
  select(-province_state, -lat, -long) %>%
  pivot_longer(cols = c(2:110), names_to = "date", values_to = "cases") %>%
  mutate(date = as_date(date, format = "x%m_%d_%y")) %>% # Convert date to a date variable
  filter(country_region %in% top10) %>%
  group_by(country_region, date) %>%
  summarise(total_cases = sum(cases)) %>%
  ggplot(aes(date, log10(total_cases))) +
  geom_line(aes(color = country_region)) +
  labs(title = "10 countries with most cases - logarithmic time series")
```

The data here shows that the US is adding more cases at a relatively linear rate, while most other countries are slowing down, with the exception of Russia and Brazil, which are seeing increasing numbers of new cases per day.

</br>

#### Analysis of US Data

From this point on in the data analysis, I decided to focus on US data. This decision was made in part because US data is more consistently available, and data such as that from the ACS is very consistent and does not have much missing data. I first plotted the time series cases and deaths for the US as a whole:

```{r, message = FALSE, warning = FALSE}
# US Focused analysis
covid_us_report <- read_csv("data/unprocessed/csse_covid_19_data/csse_covid_19_daily_reports_us/05-09-2020.csv") %>%
  clean_names()

us_confirmed_ts <- read_csv("data/unprocessed/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv") %>%
  clean_names()

us_deaths_ts <- read_csv("data/unprocessed/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv") %>%
  clean_names()

# Cases, fatalities
us_confirmed_ts <- us_confirmed_ts %>% pivot_longer(cols = 12:120, names_to = "date", values_to = "confirmed") %>%
  mutate(date = as_date(date, format = "x%m_%d_%y")) # Convert to a more usable format

us_deaths_ts <- us_deaths_ts %>% pivot_longer(cols = 13:121, names_to = "date", values_to = "deaths") %>%
  mutate(date = as_date(date, format = "x%m_%d_%y"))

us_ts <- us_confirmed_ts %>%
  group_by(date) %>%
  summarise(total_cases = sum(confirmed)) %>% left_join(
    us_deaths_ts %>%
      
      group_by(date) %>%
      
      summarise(total_deaths = sum(deaths)),
    
    by = "date")

# Plot cumulative cases and deaths:
us_ts %>% # Linear
  pivot_longer(cols = 2:3, names_to = "report", values_to = "num") %>%
  ggplot(aes(date, num)) +
  geom_line(aes(color = report)) +
  labs(title = "US Cases and Deaths - Linear")

us_ts %>% # Log
  pivot_longer(cols = 2:3, names_to = "report", values_to = "num") %>%
  ggplot(aes(date, log10(num))) +
  geom_line(aes(color = report)) +
  labs(title = "US Cases and Deaths - Logarithmic")
```

I also included a time series plot which displayed each state as a separate line, but I omitted it as it was very difficult to read.
 
</br>

### Creating New Variables

Given the nature of the data, investigating the relationship between response and predictor variables can be quite difficult. The total number of cases in a given state, for example, relies heavily on the testing capacity of that state. The mortality rate depends on how many of the actual number of people who have contracted COVID-19 are actually being tested and reported as a confirmed case. Variables such as hospitalization and incident rate are provided exclusively for US data, but there are more missing values in these variables. 

I chose to create a new variable to measure as a response variable: the daily change in the total number of deaths for each given state. This, I believed, would provide a cleaner measure of the degree to which COVID-19 is impacting each state.

From this daily rate of change variable, I created two more summary variables--the average rate of increase in deaths for each state following the 30 days after each state's first reported death, and the average rate of increase in deaths for all states in the past 10 days. The purpose for creating these summary statistics was to then compare them with various ACS variables and then see whether or not there were any significant correlations.

</br>

#### Analysis of the relationship between response variables and ACS predictors

After calculating the new summary statistics described above, I loaded four different ACS datasets on a state level - population, income, internet access, and health insurance. The analysis I did with this data could have been more thorough (i.e. county level analysis and more variables investigated), but for the purposes of this EDA I started off looking at state level data.

For each dataset, I joined together previously existing response variables and new predictor variables by state names. Then, I calculated a correlation matrix and sorted each response variable to view the most correlated predictors. I took five predictors from each of the four datasets which had a correlation of over 0.5, and added them to another dataset. 

I also repeated this process for a dataset containing total state level population counts and densities.

After taking these steps, I decided analyze the data via clustering. The initial results were very poor, due to all the predictors being highly correlated with population numbers, as they were in the form of totals (of an entire state population) rather than percentages. I converted them into percentages and the proceeded with the clustering. 

First, here is a correlation matrix:

```{r, message = FALSE, warning = FALSE}
# Creating a percent change variable: -------------------------------------

# Calculates percentage change in deaths for a given date
percent_change_deaths <- function(data){
  data %>%
    group_by(date) %>%
    summarise(deaths = sum(deaths)) %>%
    mutate(pct_change = (deaths - lag(deaths)) / lag(deaths) * 100)
}

# Run percent change function for all states
percent_change_death <- us_deaths_ts %>% group_nest(province_state) %>% 
  mutate(change = map(data, percent_change_deaths)) %>%
  select(province_state, change) %>%
  unnest(cols = c(change)) 

# Change all non-number values to NA
percent_change_death <- percent_change_death %>% 
  mutate(pct_change = ifelse(is.nan(pct_change), NA, pct_change)) %>%
  mutate(pct_change = ifelse(pct_change == Inf, NA, pct_change)) 

# Create variable for earliest death, 30 days after 
deaths_dates <- percent_change_death %>%
  filter(deaths > 0) %>%
  group_by(province_state) %>%
  summarise(first_death = min(date),
            day_30 = first_death + days(30))

# Use earliest death and 30 day period to calculate 30 day avg rate of change:
first_30 <- percent_change_death %>%
  left_join(deaths_dates, by = "province_state") %>%
  filter(date > first_death, date <= day_30) %>%
  group_by(province_state) %>%
  summarise(first30 = mean(pct_change, na.rm = TRUE)) %>%
  arrange(desc(first30))

# Average growth in deaths in past 10 days:
past_10 <- percent_change_death %>%
  filter(date >= as_date("05-01-20", format = "%m-%d-%y")) %>%
  group_by(province_state) %>%
  summarise(past10 = mean(pct_change, na.rm = TRUE)) %>%
  mutate(past10 = ifelse(is.nan(past10), 0, past10)) %>%
  arrange(desc(past10))

# Overall mean growth
overall_change <- percent_change_death %>%
  group_by(province_state) %>%
  summarise(mean_change = mean(pct_change, na.rm = TRUE)) %>%
  mutate(mean_change = ifelse(is.nan(mean_change), 0, mean_change)) %>%
  arrange(desc(mean_change))

# Add summary percent change statistics to the main dataset:
covid_us_report <- covid_us_report %>% 
  left_join(first_30, by = "province_state") %>%
  left_join(past_10, by = "province_state")

# Analysis of Predictor Variables -----------------------------------------

# Get US Data From ACS:


# Population Data ---------------------------------------------------------


acs_population <- read_csv("data/unprocessed/ACS/ACS_Total_Population_-_State.csv") %>%
  clean_names()

covid_data_pop <- covid_us_report %>%
  filter(province_state %in% acs_population$name) %>%
  rename(name = province_state) %>%
  left_join(acs_population, by = "name")

pop_corr <- covid_data_pop %>%
  select(confirmed, deaths, incident_rate, people_tested, people_hospitalized, mortality_rate,
         testing_rate, hospitalization_rate, first30, past10, 25:140) %>%
  cor() %>%
  as_tibble()

# Store most correlated variables:
covid_all_vars <- covid_data_pop %>%
  select(1:22, b01001_049e, b01001_042e, b01001_041e, b01001_040e, b01001_018e) 





# Internet Connectivity Data ----------------------------------------------

acs_internet <- read_csv("data/unprocessed/ACS/ACS_Internet_connectivity_-_State.csv") %>%
  clean_names()

covid_data_internet <- covid_us_report %>%
  filter(province_state %in% acs_internet$name) %>%
  rename(name = province_state) %>%
  left_join(acs_internet, by = "name")

internet_corr <- covid_data_internet %>%
  select(confirmed, deaths, incident_rate, people_tested, people_hospitalized, mortality_rate,
         testing_rate, hospitalization_rate, first30, past10, 25:78) %>%
  cor() %>%
  as_tibble()

covid_all_vars <- covid_all_vars %>% bind_cols(
  covid_data_internet %>%
    select(b28001_008e, b28001_011e, b28001_004e, b28002_008e, b28001_010e))

# Income Data -------------------------------------------------------------

acs_income <- read_csv("data/unprocessed/ACS/ACS_Household_Income_Distribution_-_State.csv") %>%
  clean_names()

covid_data_income <- covid_us_report %>%
  filter(province_state %in% acs_income$name) %>%
  rename(name = province_state) %>%
  left_join(acs_income, by = "name")

income_corr <- covid_data_income %>%
  select(confirmed, deaths, incident_rate, people_tested, people_hospitalized, mortality_rate,
         testing_rate, hospitalization_rate, first30, past10, 25:72) %>%
  cor() %>%
  as_tibble()

covid_all_vars <- covid_all_vars %>% bind_cols(
  covid_data_income %>%
    select(b19001_015e, b19001_002e, b19001_014e, b19001_016e, b19001_calc_num_ge100e))


# Insurance Data ----------------------------------------------------------

acs_insurance <- read_csv("data/unprocessed/ACS/ACS_Health_Insurance_Coverage_-_State.csv") %>%
  clean_names()

covid_data_insurance <- covid_us_report %>%
  filter(province_state %in% acs_income$name) %>%
  rename(name = province_state) %>%
  left_join(acs_insurance, by = "name")

insurance_corr <- covid_data_insurance %>%
  select(confirmed, deaths, incident_rate, people_tested, people_hospitalized, mortality_rate,
         testing_rate, hospitalization_rate, first30, past10, 25:93) %>%
  cor() %>%
  as_tibble()

covid_all_vars <- covid_all_vars %>% bind_cols(
  covid_data_insurance %>%
    select(b27010_036e, b27010_042e, b27010_010e, b27010_026e,
           b27010_004e))


# State Population Data ---------------------------------------------------

state_pop <- read_csv("data/unprocessed/state_population.csv") %>%
  clean_names() %>%
  rename(name = state)

covid_data_pop2 <- covid_us_report %>%
  filter(province_state %in% state_pop$name) %>%
  rename(name = province_state) %>%
  left_join(state_pop, by = "name")

pop2_corr <- covid_data_pop2 %>%
  select(confirmed, deaths, incident_rate, people_tested, people_hospitalized, mortality_rate,
         testing_rate, hospitalization_rate, first30, past10, 22:28) %>%
  cor() %>%
  as_tibble()

covid_all_vars <- covid_all_vars %>%
  bind_cols(covid_data_pop2 %>% select(pop))

# Change all variables into a percentage of population
covid_all_vars <- covid_all_vars %>% mutate_at(23:42, funs(./pop))

# Looking at all saved variables: -----------------------------------------

covid_all_vars %>%
  select(first30, past10, 23:42) %>%
  cor() %>%
  corrplot()
```

There are correlations between some of these variables, but they are not overwhelmingly correlated, as was the case before predictors were converted from totals to percentages.

Importantly, all of these predictors were moderately correlated with the `first30` variable, which is the mean growth rate in deaths during the first 30 days following the first death in each state. None of them were even moderately correlated with `past10`, which is the average rate of growth in the psat 10 days. 

Also, it is important to note that the variables were originally chosen based on how they correlated with response variables in their total, not percentage, form. Once the conversion was done, much of the correlations with the `first30` variable were eliminated. Although I did not do it in this EDA, a good next step to take might be to analyze the predictors again after converting all of them to percentages.

</br>

#### Analysis using Clustering

I performed hierarchical, K-Means, and spectral clustering on the states using only the predictors. Some of the results I obtained are shown below:

```{r, message = FALSE, warning = FALSE}
# Clustering --------------------------------------------------------------

# Helper Functions --------------------------------------------------------

# run_hclust: runs hierarchical clustering with the given method
# args: x - data used for clustering; meth - method of clustering
run_hclust <- function(x, meth){
  return(hclust(dist(x), method = meth)) # hclust runs the clustering algorithm.
}

# cut_hclust: gives desired number of clusters for an hclust() object
# args: hclust_obj - an hclust() object; ncuts - number of clusters desired
cut_hclust <- function(hclust_obj, ncuts){
  return(cutree(hclust_obj, ncuts))
}

# get_within_ss: Get within-cluster SS from a K-means object
# args: kmean_obj - a K-means obj
get_within_ss <- function(kmean_obj){
  return(kmean_obj$tot.withinss)
}

# get_cluster: get cluster labels for data
# args: x - data; clust_obj - a cluster object
get_cluster <- function(x, clust_obj){
  
  if(class(clust_obj) == "kmeans"){
    clust = clust_obj$cluster
  }
  else{
    clust = clust_obj
  }
  
  out = x %>%
    
    mutate(cluster = clust)
  
  return(out)
}


# Hierarchical Clustering -------------------------------------------------


covid_cluster_data <- covid_all_vars %>%
  select(name, 23:42)

scaled_cluster_data <- covid_cluster_data %>%
  select(2:21) %>%
  as.matrix() %>%
  scale() %>%
  as_tibble()

covid_cluster_data_scaled <- 
  covid_cluster_data %>%
  select(name) %>%
  bind_cols(scaled_cluster_data)

covid_hclust <- tibble(
  dat = covid_cluster_data_scaled %>% list()
)

covid_hclust <- covid_hclust %>%
  mutate(
    hcl = map2(dat, "complete", run_hclust), # Create clusters
    dendo = map(hcl, ggdendrogram), # Create dendrogram,
  )


covid_hclust <- covid_hclust %>%
  crossing(ncuts = c(2:6)) %>%
  mutate(
    clusters = map2(hcl, ncuts, cut_hclust),
    clust_dat = map2(dat, clusters, get_cluster)
  )

covid_hclust_6cut <- covid_hclust %>%
  filter(ncuts == 6) %>%
  select(clust_dat) %>%
  unnest(cols = c(clust_dat)) %>%
  rename(state = name) %>%
  mutate(cluster = as_factor(cluster))

# Plot 6 cluster cut on map:
plot_usmap(data = covid_hclust_6cut, values = "cluster", color = "white") +
  scale_fill_discrete(name = "Cluster", na.translate = FALSE) +
  labs(title = "Hierarchical Clustering, 6 clusters")

# K-Means Clustering ------------------------------------------------------

covid_kmeans <- tibble(xmat = list(covid_cluster_data_scaled %>% select(-name))) %>%
  crossing(nclust = 2:6)

covid_kmeans <- covid_kmeans %>% 
  mutate(
    kmean = map2(xmat, nclust, kmeans, nstart = 20),
    within_ss = map_dbl(kmean, get_within_ss),
    clusters = map2(xmat, kmean, get_cluster)
  )

covid_kmeans_5clust <- covid_kmeans %>%
  filter(nclust == 5) %>%
  select(clusters) %>%
  unnest(cols = c(clusters))

covid_kmeans_5clust <- covid_kmeans_5clust %>%
  bind_cols(covid_cluster_data_scaled %>% select(name)) %>%
  select(name, everything()) %>%
  rename(state = name) %>%
  mutate(cluster = as_factor(cluster))

# 5 Clusters
plot_usmap(data = covid_kmeans_5clust, values = "cluster", color = "white") +
  scale_fill_discrete(name = "Cluster", na.translate = FALSE) +
  labs(title = "K-Means Clustering, 5 clusters")

# Spectral Clustering -----------------------------------------------------

covid_spectral <- tibble(data = list(covid_cluster_data_scaled %>% select(-name)))

# Create spectral clusters--nclus = 5
covid_spectral <- covid_spectral %>% mutate(
  spec = map(.x = data,
             .f = function(x) specc(as.matrix(x), centers = 5)),
  spec_data = map2(data, spec, get_cluster)
)

covid_spectral_data <- covid_spectral %>%
  select(spec_data) %>%
  unnest(cols = c(spec_data)) %>%
  bind_cols(covid_cluster_data_scaled %>% select(name)) %>%
  select(name, everything()) %>%
  rename(state = name) %>%
  mutate(cluster = as_factor(as.character(cluster)))

plot_usmap(data = covid_spectral_data, values = "cluster", color = "white") +
  scale_fill_discrete(name = "Cluster", na.translate = FALSE) +
  labs(title = "Spectral Clustering, 5 clusters")

```

Note that Puerto Rico, which was not on the map, was contained in its own cluster for hierarchical and K-Means clustering. Otherwise, the results seem to be much better for K-Means and spectral than for hierarchical, which did a poor job of distinguishing between most states.

</br>

#### Comparing Cluster Results to Response Variables

In the next step, I compared various response variables separated by cluster for the K-Means and spectral methods:

```{r, message = FALSE, warning = FALSE}
# K-Means
covid_kmeans_5clust %>% select(state, cluster) %>%
  rename(province_state = state) %>%
  left_join(covid_us_report, by = "province_state") %>%
  ggplot(aes(log10(confirmed), log10(deaths))) +
  geom_point(aes(color = cluster)) +
  labs(title = "confirmed cases vs deaths by cluster, K-Means")

covid_kmeans_5clust %>% select(state, cluster) %>%
  rename(province_state = state) %>%
  left_join(covid_us_report, by = "province_state") %>%
  ggplot(aes(first30, past10)) +
  geom_point(aes(color = cluster)) +
  labs(title = "first 30 vs past 10 average rates by cluster, K-Means")

covid_kmeans_5clust %>% select(state, cluster) %>%
  rename(province_state = state) %>%
  left_join(covid_us_report, by = "province_state") %>%
  ggplot(aes(incident_rate, mortality_rate)) +
  geom_point(aes(color = cluster)) +
  labs(title = "incident_rate vs mortality rates by cluster, K-Means")

covid_kmeans_5clust %>% select(state, cluster) %>%
  rename(province_state = state) %>%
  left_join(covid_us_report, by = "province_state") %>%
  ggplot(aes(incident_rate, cluster)) +
  geom_boxplot() +
  labs(title = "incident rate by cluster, K-Means")

covid_kmeans_5clust %>% select(state, cluster) %>%
  rename(province_state = state) %>%
  left_join(covid_us_report, by = "province_state") %>%
  ggplot(aes(past10, cluster)) +
  geom_boxplot() +
  labs(title = "past10 by cluster, K-Means")

covid_kmeans_5clust %>% select(state, cluster) %>%
  rename(province_state = state) %>%
  left_join(covid_us_report, by = "province_state") %>%
  ggplot(aes(first30, cluster)) +
  geom_boxplot() +
  labs(title = "first30 by cluster, K-Means")

# Spectral
covid_spectral_data %>% select(state, cluster) %>%
  rename(province_state = state) %>%
  left_join(covid_us_report, by = "province_state") %>%
  ggplot(aes(log10(confirmed), log10(deaths))) +
  geom_point(aes(color = cluster)) +
  labs(title = "confirmed cases vs deaths by cluster, spectral")

covid_spectral_data %>% select(state, cluster) %>%
  rename(province_state = state) %>%
  left_join(covid_us_report, by = "province_state") %>%
  ggplot(aes(first30, past10)) +
  geom_point(aes(color = cluster)) +
  labs(title = "first30 vs past10 by cluster, spectral")

covid_spectral_data %>% select(state, cluster) %>%
  rename(province_state = state) %>%
  left_join(covid_us_report, by = "province_state") %>%
  ggplot(aes(incident_rate, cluster)) +
  geom_boxplot() +
  labs(title = "incident rate by cluster, spectral")

covid_spectral_data %>% select(state, cluster) %>%
  rename(province_state = state) %>%
  left_join(covid_us_report, by = "province_state") %>%
  ggplot(aes(past10, cluster)) +
  geom_boxplot() +
  labs(title = "past10 by cluster, spectral")

covid_spectral_data %>% select(state, cluster) %>%
  rename(province_state = state) %>%
  left_join(covid_us_report, by = "province_state") %>%
  ggplot(aes(first30, cluster)) +
  geom_boxplot() +
  labs(title = "first30 by cluster, spectral")
```

It appears that the clustering does not necessarily have a clear, significant effect on the response outcomes for either type of clustering. No immediate conclusions can be drawn from the results. It is likely, though, that the predictors chosen for the cluster have at most a slight effect on the response variables, based on the effects of converting the predictors from totals to percentages. 

Furthermore, there is no complete, thoroughly investigated conclusion as to why some states, such as New York and New Jersey, had much worse outbreaks than others. Unless we can identify these factors and adjust the data to account for their impact, it will be difficult to truly measure the effect of the ACS predictors on the data without deeper analysis.

#### Analysis of the Relationship between Google's Mobility Data and COVID-19 Deaths

In the next step of my EDA, I investigated whether or not Google's Community Mobility Reports might be related to day-to-day percent changes in death totals. To do this, I converted the dataset and joined it with the time-series percent change in death rates which I computed earlier. I also looked at the overall trend for the US as a whole:

```{r, message = FALSE, warning = FALSE}
# Looking at Lockdown Data ------------------------------------------------

mobility <- read_csv("data/unprocessed/global_mobility_report.csv", col_types = list(
  col_character(),
  col_character(),
  col_character(),
  col_character(),
  col_date(format = ""),
  col_double(),
  col_double(),
  col_double(),
  col_double(),
  col_double(),
  col_double()
)) %>%
  clean_names()

mobility_by_state <- mobility %>%
  filter(country_region == "United States", is.na(sub_region_2)) %>%
  group_by(sub_region_1, date) %>%
  summarise(retail_rec = mean(retail_and_recreation_percent_change_from_baseline, na.rm = TRUE),
            grocery_pharmacy = mean(grocery_and_pharmacy_percent_change_from_baseline, na.rm = TRUE),
            parks = mean(parks_percent_change_from_baseline, na.rm = TRUE),
            transit = mean(transit_stations_percent_change_from_baseline, na.rm = TRUE),
            workplace = mean(workplaces_percent_change_from_baseline, na.rm = TRUE), 
            residential = mean(residential_percent_change_from_baseline, na.rm = TRUE)) %>%
  rename(province_state = sub_region_1)

mobility_us <- mobility %>%
  filter(country_region == "United States", is.na(sub_region_1))

# Overall trend for US:
mobility_us %>%
  pivot_longer(cols = 6:11, names_to = "cat") %>%
  ggplot(aes(date, value)) +
  geom_line(aes(color = cat))
```

There are some interesting patterns in the data. The lines show the percentage difference from baseline (i.e. under normal conditions) in how often data is coming from various locations, such as at home (residential) or workplaces. Clearly, location data is showing more people at home and much less at workplaces or on transit. However, these overall trends are accompanied by fluctuations, which can be most clearly seen in the residential and workplace lines. I have not investigated these fluctuations in this EDA, but I plan to do so as a next step.

After joining together the state data, I looked at some visualizations for a few states: each plot shows the transit and residential data from Google as two separate lines, and a third line shows the daily percent change in deaths:

```{r, message = FALSE, warning = FALSE}

# Analysis by state:
mobility_analysis_states <- percent_change_death %>%
  left_join(mobility_by_state, by = c("province_state", "date"))

# Look at some states:
mobility_analysis_states %>% # Washington
  filter(province_state == "Washington") %>%
  pivot_longer(cols = c(pct_change, transit, residential), names_to = "var") %>%
  ggplot(aes(date, value)) +
  geom_line(aes(color = var)) +
  xlim(as_date("13-02-20", format = "%d-%m-%y"), as_date("07-05-20", format = "%d-%m-%y")) +
  ylim(-80, 50) + 
  labs(title = "Washington State")

mobility_analysis_states %>% # New York
  filter(province_state == "New York") %>%
  pivot_longer(cols = c(pct_change, transit, residential), names_to = "var") %>%
  ggplot(aes(date, value)) +
  geom_line(aes(color = var)) +
  xlim(as_date("13-02-20", format = "%d-%m-%y"), as_date("07-05-20", format = "%d-%m-%y")) +
  ylim(-80, 50) +
  labs(title = "New York State")

mobility_analysis_states %>% # Mississippi
  filter(province_state == "Mississippi") %>%
  pivot_longer(cols = c(pct_change, transit, residential), names_to = "var") %>%
  ggplot(aes(date, value)) +
  geom_line(aes(color = var)) +
  xlim(as_date("13-02-20", format = "%d-%m-%y"), as_date("07-05-20", format = "%d-%m-%y")) +
  ylim(-80, 50) + 
  labs(title = "Mississippi")

mobility_analysis_states %>% # Illinois
  filter(province_state == "Illinois") %>%
  pivot_longer(cols = c(pct_change, transit, residential), names_to = "var") %>%
  ggplot(aes(date, value)) +
  geom_line(aes(color = var)) +
  xlim(as_date("13-02-20", format = "%d-%m-%y"), as_date("07-05-20", format = "%d-%m-%y")) +
  ylim(-80, 50) +
  labs(title = "Illinois")



```

There's a clear trend in the plots: all four states showed signs of people going to work less and staying home more. This is accompanied by a decrease in the percent change in death rates. Mississippi, which has shown somewhat of an increase in mobility recently, also sees a spike in death rates towards the most recent dates displayed. This data certainly supports the hypothesis that lockdowns can slow down the amount of deaths caused by COVID-19, and as some states ease lockdown policies, more data will be available in the coming weeks which provides more insight as to whether or not the easing of lockdowns can cause deaths to spike again.

</br> 

### Conclusion

Although I end the EDA here, there is still much to be investigated. Most of this EDA was dedicated to finding variables which show promise in possibly explaining the trends in how COVID-19 affects the US and its communities. I have found that, on a state level, there is no strong evidence to suggest that any of the variables from the four ACS datasets which I used have a significant relationship with COVID-19 statistics. However, to be sure, more analyses should be done on a county level. Also, I have found that mobility data could potentially serve as a good predictor of COVID-19 related trends. 

The next steps involve continuing to search for potential variables that can influence the impact of COVID-19. For example, there have been reports that COVID-19 is affecting Black and Latino communities disproportionally, perhaps due to socioeconomic factors and the presence of more comorbidities. More time should be dedicated to exploring how mobility data can be used to model the future trajectory of COVID-19 deaths, as well as how both of these might be impacted by government.

</br>

### Data Processing:

The time series data which was used for model-building was formatted such that there were columns for states and dates, and to find the total number of deaths on a certain date, one would need to look under the state column to find the row which corresponded to the desired state, then find the column which corresponded to the desired date. 

I first changed the format of the data by creating a date column which indicated the date, rather than having one column for each individual date. This converted the data to a much longer form, and helped with visualizations as well as further processing.

The data was then summarised from county level to state level. Google and Apple mobility data were also filtered and summarised to US state-level data before being joined to the main dataset. Next, lag variables from 1-14 days were calculated and inserted into the data, and then rolling averages of mobility data were calculated, and then lag variables for these rolling averages.

Finally, a tibble containing the name of each state and the date of its first recorded death was constructed. This tibble was then joined to the primary dataset, and a new variable, the difference between the date of the first death and the date of the observation, was added. The primary dataset was then saved to be used for various model-building scripts.

### Data Sources:

Census COVID-19 Data Hub. Retrieved from https://covid19.census.gov/

COVID-19 Dashboard by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University. (2020, April 24). Retrieved from https://github.com/CSSEGISandData/COVID-19

COVID‑19 - Mobility Trends Reports. (2020, June 1). Retrieved from https://www.apple.com/covid19/mobility

Google LLC "Google COVID-19 Community Mobility Reports" Retrieved from https://www.google.com/covid19/mobility/

US States - Ranked by Population 2020. Retrieved from https://worldpopulationreview.com/states/






